{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_0\n",
      "Gradient check passed!\n",
      "Checking gradient for B_0\n",
      "Gradient check passed!\n",
      "Checking gradient for W_2\n",
      "Gradient check passed!\n",
      "Checking gradient for B_2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_0\n",
      "Gradient check passed!\n",
      "Checking gradient for B_0\n",
      "Gradient check passed!\n",
      "Checking gradient for W_2\n",
      "Gradient check passed!\n",
      "Checking gradient for B_2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss_with_reg, loss)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!https://github.com/olegpolivin/dlcourse_ai.git\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.216398, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153856, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.099106, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285874, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.168890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.063678, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.365672, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.103934, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.222549, Train accuracy: 0.210333, val accuracy: 0.218000\n",
      "Loss: 2.059842, Train accuracy: 0.233111, val accuracy: 0.237000\n",
      "Loss: 2.115231, Train accuracy: 0.260667, val accuracy: 0.257000\n",
      "Loss: 2.090787, Train accuracy: 0.272111, val accuracy: 0.275000\n",
      "Loss: 2.098957, Train accuracy: 0.288222, val accuracy: 0.292000\n",
      "Loss: 1.974340, Train accuracy: 0.306889, val accuracy: 0.310000\n",
      "Loss: 2.011588, Train accuracy: 0.333000, val accuracy: 0.336000\n",
      "Loss: 1.819071, Train accuracy: 0.369444, val accuracy: 0.366000\n",
      "Loss: 1.805035, Train accuracy: 0.398222, val accuracy: 0.391000\n",
      "Loss: 2.001364, Train accuracy: 0.415444, val accuracy: 0.405000\n",
      "Loss: 1.930639, Train accuracy: 0.435778, val accuracy: 0.432000\n",
      "Loss: 1.738233, Train accuracy: 0.467111, val accuracy: 0.463000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f823c08f610>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8225b75e50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history, label='Train accuracy')\n",
    "plt.plot(val_history, label='Val accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.245382, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.372504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207905, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259103, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180887, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191641, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.081185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.321212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246704, Train accuracy: 0.202778, val accuracy: 0.212000\n",
      "Loss: 2.189141, Train accuracy: 0.231111, val accuracy: 0.238000\n",
      "Loss: 2.074268, Train accuracy: 0.243778, val accuracy: 0.247000\n",
      "Loss: 2.086563, Train accuracy: 0.271111, val accuracy: 0.272000\n",
      "Loss: 2.373452, Train accuracy: 0.278222, val accuracy: 0.275000\n",
      "Loss: 1.735182, Train accuracy: 0.284444, val accuracy: 0.289000\n",
      "Loss: 2.276342, Train accuracy: 0.307667, val accuracy: 0.311000\n",
      "Loss: 1.906094, Train accuracy: 0.339778, val accuracy: 0.338000\n",
      "Loss: 1.673473, Train accuracy: 0.373222, val accuracy: 0.373000\n",
      "Loss: 1.652354, Train accuracy: 0.395778, val accuracy: 0.388000\n",
      "Loss: 1.616790, Train accuracy: 0.415444, val accuracy: 0.411000\n",
      "Loss: 1.999104, Train accuracy: 0.444889, val accuracy: 0.437000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.144626, Train accuracy: 0.197333, val accuracy: 0.206000\n",
      "Loss: 1.622121, Train accuracy: 0.355222, val accuracy: 0.358000\n",
      "Loss: 1.265590, Train accuracy: 0.554000, val accuracy: 0.547000\n",
      "Loss: 1.426333, Train accuracy: 0.609222, val accuracy: 0.590000\n",
      "Loss: 1.316831, Train accuracy: 0.673889, val accuracy: 0.653000\n",
      "Loss: 1.585551, Train accuracy: 0.671222, val accuracy: 0.662000\n",
      "Loss: 0.881241, Train accuracy: 0.727556, val accuracy: 0.678000\n",
      "Loss: 0.963371, Train accuracy: 0.728889, val accuracy: 0.666000\n",
      "Loss: 0.960361, Train accuracy: 0.750222, val accuracy: 0.703000\n",
      "Loss: 1.111276, Train accuracy: 0.773000, val accuracy: 0.697000\n",
      "Loss: 0.505593, Train accuracy: 0.783444, val accuracy: 0.709000\n",
      "Loss: 0.590929, Train accuracy: 0.811667, val accuracy: 0.725000\n",
      "Loss: 0.583194, Train accuracy: 0.829333, val accuracy: 0.728000\n",
      "Loss: 0.286914, Train accuracy: 0.804000, val accuracy: 0.719000\n",
      "Loss: 1.040563, Train accuracy: 0.835000, val accuracy: 0.731000\n",
      "Loss: 0.458959, Train accuracy: 0.829111, val accuracy: 0.744000\n",
      "Loss: 0.643442, Train accuracy: 0.835778, val accuracy: 0.732000\n",
      "Loss: 0.731865, Train accuracy: 0.836111, val accuracy: 0.727000\n",
      "Loss: 0.157285, Train accuracy: 0.869444, val accuracy: 0.763000\n",
      "Loss: 0.417178, Train accuracy: 0.863222, val accuracy: 0.741000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351801, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319693, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.295926, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.345443, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310013, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.326544, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.255641, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199259, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.164561, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.025661, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883798, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.263931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.662918, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.245522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943906, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.663953, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.042200, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.418303, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.519709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.823944, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.585656, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937038, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908215, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.233499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.095108, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.718242, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.162756, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.015933, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.363952, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.842670, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.657567, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.388463, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.911120, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.693765, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.010436, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.115900, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613706, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.738574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.885192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.474042, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.119274, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.672047, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.767860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.478802, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.926619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.337383, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.683186, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.660081, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.401881, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.635264, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.635617, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.622938, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.854111, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.556636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634732, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.076198, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.007559, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.531114, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.041336, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.022564, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369538, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.379903, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.986917, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318972, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.283966, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936269, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.196061, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.739352, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.201189, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.582981, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.742143, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.293135, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.748190, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.976545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.357876, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.992895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602046, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602167, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.173057, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.312798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.564551, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.961713, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.274091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.304703, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.958926, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.377168, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.657193, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.389767, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.576803, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.556738, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.175409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322616, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.251510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.060407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.661861, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227308, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.597969, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.887250, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.338688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.842966, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.160604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.347215, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223119, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.436648, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.535320, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249121, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.248964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.549803, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.259687, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097239, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.324286, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.315431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.420746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443017, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.301618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.533658, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.607993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.239065, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.649177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.602848, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.363682, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.197888, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.126413, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.008120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.643235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.592807, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412599, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.212850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196541, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.280346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.403204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229377, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.102808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.445285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219193, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449330, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.304464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.494726, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.361608, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.424061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.303493, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.272501, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.112325, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.223673, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.279593, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.022219, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.724254, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.406655, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.777473, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.856513, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.829882, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 0.995744, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 0.922113, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.554490, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.440609, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.336933, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.380880, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.278951, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.291828, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.060600, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=0.33, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea will be the following: first, we choose among large range of parameters, and then I will adjust further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 300\n",
      "Loss: 2.326941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.109972, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253461, Train accuracy: 0.255667, val accuracy: 0.250000\n",
      "Loss: 1.991817, Train accuracy: 0.282889, val accuracy: 0.280000\n",
      "Loss: 1.873679, Train accuracy: 0.347556, val accuracy: 0.343000\n",
      "Loss: 1.681974, Train accuracy: 0.411556, val accuracy: 0.399000\n",
      "Loss: 1.506193, Train accuracy: 0.447444, val accuracy: 0.437000\n",
      "Loss: 1.357056, Train accuracy: 0.482333, val accuracy: 0.485000\n",
      "Loss: 1.700768, Train accuracy: 0.518000, val accuracy: 0.517000\n",
      "Loss: 1.372289, Train accuracy: 0.535889, val accuracy: 0.534000\n",
      "Loss: 1.423331, Train accuracy: 0.568778, val accuracy: 0.566000\n",
      "Loss: 1.329288, Train accuracy: 0.582000, val accuracy: 0.571000\n",
      "Loss: 1.139940, Train accuracy: 0.602333, val accuracy: 0.586000\n",
      "Loss: 1.310450, Train accuracy: 0.609556, val accuracy: 0.596000\n",
      "Loss: 1.135023, Train accuracy: 0.620556, val accuracy: 0.598000\n",
      "Loss: 1.177154, Train accuracy: 0.623667, val accuracy: 0.604000\n",
      "Loss: 1.098660, Train accuracy: 0.637778, val accuracy: 0.622000\n",
      "Loss: 1.247698, Train accuracy: 0.644333, val accuracy: 0.625000\n",
      "Loss: 1.071508, Train accuracy: 0.647000, val accuracy: 0.622000\n",
      "Loss: 0.955026, Train accuracy: 0.649444, val accuracy: 0.632000\n",
      "Loss: 0.833773, Train accuracy: 0.654444, val accuracy: 0.636000\n",
      "Loss: 1.295309, Train accuracy: 0.658444, val accuracy: 0.635000\n",
      "Loss: 1.188817, Train accuracy: 0.663778, val accuracy: 0.638000\n",
      "Loss: 1.094423, Train accuracy: 0.664000, val accuracy: 0.649000\n",
      "Loss: 1.252804, Train accuracy: 0.666556, val accuracy: 0.646000\n",
      "Loss: 1.043815, Train accuracy: 0.668556, val accuracy: 0.649000\n",
      "Loss: 1.320777, Train accuracy: 0.670667, val accuracy: 0.649000\n",
      "Loss: 0.957287, Train accuracy: 0.671444, val accuracy: 0.649000\n",
      "Loss: 0.911503, Train accuracy: 0.674111, val accuracy: 0.653000\n",
      "Loss: 1.089456, Train accuracy: 0.673667, val accuracy: 0.651000\n",
      "Loss: 1.167204, Train accuracy: 0.676111, val accuracy: 0.653000\n",
      "Loss: 0.895224, Train accuracy: 0.676889, val accuracy: 0.653000\n",
      "Loss: 1.136188, Train accuracy: 0.676444, val accuracy: 0.652000\n",
      "Loss: 1.250259, Train accuracy: 0.678222, val accuracy: 0.657000\n",
      "Loss: 0.940047, Train accuracy: 0.678222, val accuracy: 0.655000\n",
      "Loss: 0.970255, Train accuracy: 0.678778, val accuracy: 0.655000\n",
      "Loss: 0.964541, Train accuracy: 0.679000, val accuracy: 0.657000\n",
      "Loss: 1.309370, Train accuracy: 0.679889, val accuracy: 0.653000\n",
      "Loss: 1.191095, Train accuracy: 0.680667, val accuracy: 0.655000\n",
      "Loss: 0.932554, Train accuracy: 0.680222, val accuracy: 0.655000\n",
      "Loss: 1.171181, Train accuracy: 0.681667, val accuracy: 0.656000\n",
      "Loss: 1.292358, Train accuracy: 0.681333, val accuracy: 0.656000\n",
      "Loss: 1.035191, Train accuracy: 0.681444, val accuracy: 0.658000\n",
      "Loss: 1.130741, Train accuracy: 0.681778, val accuracy: 0.658000\n",
      "Loss: 1.009058, Train accuracy: 0.683111, val accuracy: 0.658000\n",
      "Loss: 1.007729, Train accuracy: 0.683444, val accuracy: 0.660000\n",
      "Loss: 1.205300, Train accuracy: 0.682889, val accuracy: 0.660000\n",
      "Loss: 1.119638, Train accuracy: 0.683889, val accuracy: 0.660000\n",
      "Loss: 1.042542, Train accuracy: 0.683667, val accuracy: 0.660000\n",
      "Loss: 0.840579, Train accuracy: 0.683889, val accuracy: 0.661000\n",
      "Loss: 1.035708, Train accuracy: 0.684000, val accuracy: 0.660000\n",
      "Loss: 0.923707, Train accuracy: 0.684000, val accuracy: 0.660000\n",
      "Loss: 0.965050, Train accuracy: 0.684222, val accuracy: 0.660000\n",
      "Loss: 1.123647, Train accuracy: 0.684222, val accuracy: 0.661000\n",
      "Loss: 0.955366, Train accuracy: 0.684111, val accuracy: 0.661000\n",
      "Loss: 0.814398, Train accuracy: 0.684444, val accuracy: 0.661000\n",
      "Loss: 0.968253, Train accuracy: 0.684222, val accuracy: 0.661000\n",
      "Loss: 1.423934, Train accuracy: 0.684556, val accuracy: 0.661000\n",
      "Loss: 0.966348, Train accuracy: 0.684778, val accuracy: 0.661000\n",
      "Loss: 1.009380, Train accuracy: 0.684667, val accuracy: 0.661000\n",
      "Loss: 0.895788, Train accuracy: 0.685111, val accuracy: 0.661000\n",
      "Loss: 1.030007, Train accuracy: 0.684889, val accuracy: 0.661000\n",
      "Loss: 1.283871, Train accuracy: 0.684889, val accuracy: 0.661000\n",
      "Loss: 0.885904, Train accuracy: 0.685111, val accuracy: 0.661000\n",
      "Loss: 0.953155, Train accuracy: 0.684889, val accuracy: 0.661000\n",
      "Loss: 1.119136, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.137038, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.326291, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.172828, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.255670, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.060216, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.131788, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.234611, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.185655, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.006404, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.262021, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 0.726051, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 0.922101, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 0.837888, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 0.902379, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 0.861731, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 0.791747, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 1.051046, Train accuracy: 0.685000, val accuracy: 0.661000\n",
      "Loss: 0.814961, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.881616, Train accuracy: 0.685111, val accuracy: 0.661000\n",
      "Loss: 1.157032, Train accuracy: 0.685111, val accuracy: 0.661000\n",
      "Loss: 1.163290, Train accuracy: 0.685111, val accuracy: 0.661000\n",
      "Loss: 1.006947, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.976515, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.951047, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.125404, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.935596, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.054655, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.273065, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.936834, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.146374, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.225637, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.828790, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.965254, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.166722, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.380520, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.052493, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.065439, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.300010, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.075835, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.105461, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.291338, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.232329, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.037717, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.001371, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.141460, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.162190, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.980506, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.205017, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.014760, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.178157, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.117697, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.148229, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.114655, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.039544, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.078872, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.751222, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.152782, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.098992, Train accuracy: 0.685222, val accuracy: 0.661000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.037857, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.979279, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.207899, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.086362, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.341553, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.133942, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.717548, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.286119, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.021807, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.137245, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.178175, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.972548, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.041782, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.999855, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.245629, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.282257, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.979407, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.973458, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.970251, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.150892, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.756359, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.980973, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.811263, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.789807, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.109221, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.257582, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.234022, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.247491, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.926965, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.134887, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.411531, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.971191, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.869212, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.358273, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.159801, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.932767, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.337094, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.012824, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.992531, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.147651, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.275823, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.466298, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.158058, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.043721, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.988979, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.863969, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.930218, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.056281, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.180498, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.710265, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.803282, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.113783, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.789104, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.111920, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.115972, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.060828, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.133785, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.135869, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.249458, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.122524, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.886011, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.264380, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.059769, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.074070, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.600760, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.977781, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.025358, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.782059, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.008097, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.987067, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.255152, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.094046, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.019167, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 1.229541, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Loss: 0.992390, Train accuracy: 0.685222, val accuracy: 0.661000\n",
      "Resulting accuracy is 0.661\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 300\n",
      "Loss: 2.246610, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.182784, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152632, Train accuracy: 0.214667, val accuracy: 0.219000\n",
      "Loss: 1.999060, Train accuracy: 0.274222, val accuracy: 0.276000\n",
      "Loss: 1.896302, Train accuracy: 0.373111, val accuracy: 0.370000\n",
      "Loss: 1.727630, Train accuracy: 0.450333, val accuracy: 0.446000\n",
      "Loss: 1.358273, Train accuracy: 0.527000, val accuracy: 0.514000\n",
      "Loss: 1.068473, Train accuracy: 0.575778, val accuracy: 0.555000\n",
      "Loss: 1.481829, Train accuracy: 0.624444, val accuracy: 0.592000\n",
      "Loss: 1.059872, Train accuracy: 0.658222, val accuracy: 0.633000\n",
      "Loss: 1.086667, Train accuracy: 0.672889, val accuracy: 0.648000\n",
      "Loss: 0.987035, Train accuracy: 0.690333, val accuracy: 0.674000\n",
      "Loss: 0.965388, Train accuracy: 0.702222, val accuracy: 0.690000\n",
      "Loss: 0.990625, Train accuracy: 0.721333, val accuracy: 0.704000\n",
      "Loss: 0.853697, Train accuracy: 0.727222, val accuracy: 0.692000\n",
      "Loss: 0.919254, Train accuracy: 0.732222, val accuracy: 0.699000\n",
      "Loss: 1.093859, Train accuracy: 0.745778, val accuracy: 0.710000\n",
      "Loss: 0.647032, Train accuracy: 0.765667, val accuracy: 0.715000\n",
      "Loss: 0.721304, Train accuracy: 0.766556, val accuracy: 0.715000\n",
      "Loss: 0.774857, Train accuracy: 0.773111, val accuracy: 0.707000\n",
      "Loss: 0.603767, Train accuracy: 0.785667, val accuracy: 0.728000\n",
      "Loss: 0.591546, Train accuracy: 0.783111, val accuracy: 0.719000\n",
      "Loss: 0.618235, Train accuracy: 0.787000, val accuracy: 0.729000\n",
      "Loss: 0.699833, Train accuracy: 0.801222, val accuracy: 0.737000\n",
      "Loss: 0.714653, Train accuracy: 0.816333, val accuracy: 0.729000\n",
      "Loss: 0.711657, Train accuracy: 0.831333, val accuracy: 0.743000\n",
      "Loss: 0.492397, Train accuracy: 0.831111, val accuracy: 0.736000\n",
      "Loss: 0.657324, Train accuracy: 0.834889, val accuracy: 0.755000\n",
      "Loss: 0.290511, Train accuracy: 0.843222, val accuracy: 0.753000\n",
      "Loss: 0.554243, Train accuracy: 0.838889, val accuracy: 0.747000\n",
      "Loss: 0.657244, Train accuracy: 0.847889, val accuracy: 0.749000\n",
      "Loss: 0.765849, Train accuracy: 0.852556, val accuracy: 0.752000\n",
      "Loss: 0.318537, Train accuracy: 0.854333, val accuracy: 0.744000\n",
      "Loss: 0.738688, Train accuracy: 0.868667, val accuracy: 0.757000\n",
      "Loss: 0.304367, Train accuracy: 0.873222, val accuracy: 0.758000\n",
      "Loss: 0.553022, Train accuracy: 0.878778, val accuracy: 0.755000\n",
      "Loss: 0.577748, Train accuracy: 0.883000, val accuracy: 0.764000\n",
      "Loss: 0.322372, Train accuracy: 0.879556, val accuracy: 0.762000\n",
      "Loss: 0.399843, Train accuracy: 0.887556, val accuracy: 0.757000\n",
      "Loss: 0.531690, Train accuracy: 0.899222, val accuracy: 0.769000\n",
      "Loss: 0.381896, Train accuracy: 0.894222, val accuracy: 0.766000\n",
      "Loss: 0.191804, Train accuracy: 0.885111, val accuracy: 0.752000\n",
      "Loss: 0.407833, Train accuracy: 0.889667, val accuracy: 0.757000\n",
      "Loss: 0.473991, Train accuracy: 0.904667, val accuracy: 0.762000\n",
      "Loss: 0.445965, Train accuracy: 0.912556, val accuracy: 0.764000\n",
      "Loss: 0.352739, Train accuracy: 0.909111, val accuracy: 0.768000\n",
      "Loss: 0.420482, Train accuracy: 0.914111, val accuracy: 0.765000\n",
      "Loss: 0.385926, Train accuracy: 0.922333, val accuracy: 0.773000\n",
      "Loss: 0.274653, Train accuracy: 0.920444, val accuracy: 0.767000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.210513, Train accuracy: 0.926000, val accuracy: 0.772000\n",
      "Loss: 0.313489, Train accuracy: 0.922444, val accuracy: 0.773000\n",
      "Loss: 0.330036, Train accuracy: 0.916667, val accuracy: 0.759000\n",
      "Loss: 0.157636, Train accuracy: 0.930556, val accuracy: 0.776000\n",
      "Loss: 0.396174, Train accuracy: 0.937889, val accuracy: 0.777000\n",
      "Loss: 0.397930, Train accuracy: 0.926778, val accuracy: 0.765000\n",
      "Loss: 0.271690, Train accuracy: 0.939667, val accuracy: 0.775000\n",
      "Loss: 0.279854, Train accuracy: 0.942222, val accuracy: 0.777000\n",
      "Loss: 0.350314, Train accuracy: 0.938222, val accuracy: 0.770000\n",
      "Loss: 0.206109, Train accuracy: 0.944889, val accuracy: 0.778000\n",
      "Loss: 0.324419, Train accuracy: 0.949889, val accuracy: 0.768000\n",
      "Loss: 0.249505, Train accuracy: 0.947000, val accuracy: 0.772000\n",
      "Loss: 0.158831, Train accuracy: 0.940667, val accuracy: 0.773000\n",
      "Loss: 0.243334, Train accuracy: 0.949778, val accuracy: 0.768000\n",
      "Loss: 0.259721, Train accuracy: 0.955889, val accuracy: 0.768000\n",
      "Loss: 0.323820, Train accuracy: 0.958222, val accuracy: 0.773000\n",
      "Loss: 0.164227, Train accuracy: 0.953444, val accuracy: 0.774000\n",
      "Loss: 0.246988, Train accuracy: 0.957778, val accuracy: 0.775000\n",
      "Loss: 0.159775, Train accuracy: 0.949889, val accuracy: 0.773000\n",
      "Loss: 0.197916, Train accuracy: 0.957000, val accuracy: 0.778000\n",
      "Loss: 0.181836, Train accuracy: 0.955556, val accuracy: 0.775000\n",
      "Loss: 0.314706, Train accuracy: 0.965556, val accuracy: 0.781000\n",
      "Loss: 0.087408, Train accuracy: 0.964667, val accuracy: 0.775000\n",
      "Loss: 0.116309, Train accuracy: 0.966889, val accuracy: 0.770000\n",
      "Loss: 0.273693, Train accuracy: 0.966556, val accuracy: 0.769000\n",
      "Loss: 0.299609, Train accuracy: 0.960111, val accuracy: 0.777000\n",
      "Loss: 0.135970, Train accuracy: 0.968889, val accuracy: 0.777000\n",
      "Loss: 0.262696, Train accuracy: 0.971111, val accuracy: 0.778000\n",
      "Loss: 0.243597, Train accuracy: 0.970778, val accuracy: 0.772000\n",
      "Loss: 0.200096, Train accuracy: 0.968111, val accuracy: 0.780000\n",
      "Loss: 0.236018, Train accuracy: 0.975111, val accuracy: 0.780000\n",
      "Loss: 0.270119, Train accuracy: 0.976000, val accuracy: 0.783000\n",
      "Loss: 0.151752, Train accuracy: 0.974556, val accuracy: 0.780000\n",
      "Loss: 0.085921, Train accuracy: 0.976889, val accuracy: 0.780000\n",
      "Loss: 0.123501, Train accuracy: 0.973000, val accuracy: 0.781000\n",
      "Loss: 0.063508, Train accuracy: 0.978222, val accuracy: 0.780000\n",
      "Loss: 0.234204, Train accuracy: 0.978000, val accuracy: 0.781000\n",
      "Loss: 0.166901, Train accuracy: 0.978444, val accuracy: 0.781000\n",
      "Loss: 0.173086, Train accuracy: 0.979889, val accuracy: 0.781000\n",
      "Loss: 0.073552, Train accuracy: 0.977889, val accuracy: 0.779000\n",
      "Loss: 0.210100, Train accuracy: 0.980333, val accuracy: 0.781000\n",
      "Loss: 0.147538, Train accuracy: 0.981778, val accuracy: 0.784000\n",
      "Loss: 0.104947, Train accuracy: 0.980889, val accuracy: 0.790000\n",
      "Loss: 0.127510, Train accuracy: 0.982111, val accuracy: 0.786000\n",
      "Loss: 0.129319, Train accuracy: 0.985222, val accuracy: 0.780000\n",
      "Loss: 0.170562, Train accuracy: 0.980556, val accuracy: 0.776000\n",
      "Loss: 0.192765, Train accuracy: 0.983222, val accuracy: 0.784000\n",
      "Loss: 0.105192, Train accuracy: 0.983556, val accuracy: 0.781000\n",
      "Loss: 0.152386, Train accuracy: 0.986111, val accuracy: 0.783000\n",
      "Loss: 0.133889, Train accuracy: 0.986111, val accuracy: 0.783000\n",
      "Loss: 0.107945, Train accuracy: 0.985889, val accuracy: 0.781000\n",
      "Loss: 0.152160, Train accuracy: 0.988000, val accuracy: 0.781000\n",
      "Loss: 0.088482, Train accuracy: 0.986778, val accuracy: 0.781000\n",
      "Loss: 0.079783, Train accuracy: 0.983111, val accuracy: 0.778000\n",
      "Loss: 0.089886, Train accuracy: 0.987667, val accuracy: 0.784000\n",
      "Loss: 0.169425, Train accuracy: 0.986444, val accuracy: 0.781000\n",
      "Loss: 0.156517, Train accuracy: 0.989000, val accuracy: 0.781000\n",
      "Loss: 0.168665, Train accuracy: 0.988889, val accuracy: 0.778000\n",
      "Loss: 0.129939, Train accuracy: 0.987778, val accuracy: 0.783000\n",
      "Loss: 0.213256, Train accuracy: 0.986556, val accuracy: 0.778000\n",
      "Loss: 0.098309, Train accuracy: 0.989667, val accuracy: 0.777000\n",
      "Loss: 0.090124, Train accuracy: 0.990333, val accuracy: 0.781000\n",
      "Loss: 0.098363, Train accuracy: 0.989889, val accuracy: 0.780000\n",
      "Loss: 0.074627, Train accuracy: 0.990000, val accuracy: 0.780000\n",
      "Loss: 0.138986, Train accuracy: 0.988333, val accuracy: 0.777000\n",
      "Loss: 0.050246, Train accuracy: 0.991556, val accuracy: 0.779000\n",
      "Loss: 0.102428, Train accuracy: 0.989667, val accuracy: 0.784000\n",
      "Loss: 0.093152, Train accuracy: 0.991444, val accuracy: 0.783000\n",
      "Loss: 0.095579, Train accuracy: 0.991556, val accuracy: 0.782000\n",
      "Loss: 0.174250, Train accuracy: 0.991778, val accuracy: 0.785000\n",
      "Loss: 0.105386, Train accuracy: 0.991556, val accuracy: 0.784000\n",
      "Loss: 0.087326, Train accuracy: 0.992000, val accuracy: 0.779000\n",
      "Loss: 0.139960, Train accuracy: 0.992889, val accuracy: 0.785000\n",
      "Loss: 0.073980, Train accuracy: 0.992444, val accuracy: 0.781000\n",
      "Loss: 0.118519, Train accuracy: 0.992556, val accuracy: 0.787000\n",
      "Loss: 0.117093, Train accuracy: 0.993000, val accuracy: 0.784000\n",
      "Loss: 0.091582, Train accuracy: 0.992556, val accuracy: 0.780000\n",
      "Loss: 0.085084, Train accuracy: 0.993444, val accuracy: 0.783000\n",
      "Loss: 0.109809, Train accuracy: 0.992667, val accuracy: 0.782000\n",
      "Loss: 0.082735, Train accuracy: 0.992778, val accuracy: 0.782000\n",
      "Loss: 0.115125, Train accuracy: 0.991778, val accuracy: 0.778000\n",
      "Loss: 0.068877, Train accuracy: 0.993000, val accuracy: 0.783000\n",
      "Loss: 0.092309, Train accuracy: 0.992778, val accuracy: 0.784000\n",
      "Loss: 0.113193, Train accuracy: 0.994111, val accuracy: 0.785000\n",
      "Loss: 0.110884, Train accuracy: 0.992667, val accuracy: 0.782000\n",
      "Loss: 0.082438, Train accuracy: 0.993111, val accuracy: 0.785000\n",
      "Loss: 0.074502, Train accuracy: 0.993444, val accuracy: 0.779000\n",
      "Loss: 0.074755, Train accuracy: 0.994444, val accuracy: 0.786000\n",
      "Loss: 0.082477, Train accuracy: 0.994333, val accuracy: 0.784000\n",
      "Loss: 0.120853, Train accuracy: 0.994556, val accuracy: 0.783000\n",
      "Loss: 0.112348, Train accuracy: 0.994333, val accuracy: 0.780000\n",
      "Loss: 0.057082, Train accuracy: 0.994111, val accuracy: 0.784000\n",
      "Loss: 0.137367, Train accuracy: 0.994667, val accuracy: 0.782000\n",
      "Loss: 0.078917, Train accuracy: 0.994222, val accuracy: 0.782000\n",
      "Loss: 0.053258, Train accuracy: 0.994778, val accuracy: 0.778000\n",
      "Loss: 0.098779, Train accuracy: 0.995556, val accuracy: 0.781000\n",
      "Loss: 0.102895, Train accuracy: 0.994889, val accuracy: 0.781000\n",
      "Loss: 0.086997, Train accuracy: 0.994889, val accuracy: 0.782000\n",
      "Loss: 0.053876, Train accuracy: 0.996000, val accuracy: 0.785000\n",
      "Loss: 0.078287, Train accuracy: 0.995889, val accuracy: 0.784000\n",
      "Loss: 0.064197, Train accuracy: 0.995667, val accuracy: 0.785000\n",
      "Loss: 0.047172, Train accuracy: 0.995444, val accuracy: 0.783000\n",
      "Loss: 0.049465, Train accuracy: 0.995667, val accuracy: 0.778000\n",
      "Loss: 0.068770, Train accuracy: 0.995667, val accuracy: 0.782000\n",
      "Loss: 0.078535, Train accuracy: 0.995667, val accuracy: 0.782000\n",
      "Loss: 0.054575, Train accuracy: 0.996000, val accuracy: 0.783000\n",
      "Loss: 0.148528, Train accuracy: 0.995889, val accuracy: 0.783000\n",
      "Loss: 0.071105, Train accuracy: 0.996111, val accuracy: 0.777000\n",
      "Loss: 0.070900, Train accuracy: 0.996444, val accuracy: 0.780000\n",
      "Loss: 0.111392, Train accuracy: 0.996000, val accuracy: 0.783000\n",
      "Loss: 0.051642, Train accuracy: 0.995667, val accuracy: 0.779000\n",
      "Loss: 0.040295, Train accuracy: 0.995778, val accuracy: 0.783000\n",
      "Loss: 0.079202, Train accuracy: 0.995889, val accuracy: 0.778000\n",
      "Loss: 0.079288, Train accuracy: 0.996556, val accuracy: 0.786000\n",
      "Loss: 0.113282, Train accuracy: 0.996000, val accuracy: 0.783000\n",
      "Loss: 0.059202, Train accuracy: 0.996222, val accuracy: 0.781000\n",
      "Loss: 0.044710, Train accuracy: 0.996444, val accuracy: 0.783000\n",
      "Loss: 0.099282, Train accuracy: 0.996667, val accuracy: 0.782000\n",
      "Loss: 0.090899, Train accuracy: 0.996444, val accuracy: 0.777000\n",
      "Loss: 0.055726, Train accuracy: 0.996778, val accuracy: 0.780000\n",
      "Loss: 0.054078, Train accuracy: 0.996556, val accuracy: 0.782000\n",
      "Loss: 0.092154, Train accuracy: 0.997000, val accuracy: 0.784000\n",
      "Loss: 0.041153, Train accuracy: 0.996889, val accuracy: 0.784000\n",
      "Loss: 0.070984, Train accuracy: 0.996778, val accuracy: 0.781000\n",
      "Loss: 0.116802, Train accuracy: 0.996889, val accuracy: 0.781000\n",
      "Loss: 0.078985, Train accuracy: 0.996333, val accuracy: 0.777000\n",
      "Loss: 0.106138, Train accuracy: 0.997000, val accuracy: 0.783000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.099782, Train accuracy: 0.997111, val accuracy: 0.777000\n",
      "Loss: 0.054831, Train accuracy: 0.997111, val accuracy: 0.778000\n",
      "Loss: 0.111454, Train accuracy: 0.996889, val accuracy: 0.779000\n",
      "Loss: 0.054191, Train accuracy: 0.996667, val accuracy: 0.779000\n",
      "Loss: 0.103092, Train accuracy: 0.997333, val accuracy: 0.778000\n",
      "Loss: 0.104503, Train accuracy: 0.996889, val accuracy: 0.776000\n",
      "Loss: 0.096330, Train accuracy: 0.997222, val accuracy: 0.781000\n",
      "Loss: 0.073081, Train accuracy: 0.997444, val accuracy: 0.779000\n",
      "Loss: 0.094699, Train accuracy: 0.997111, val accuracy: 0.780000\n",
      "Loss: 0.041691, Train accuracy: 0.997444, val accuracy: 0.781000\n",
      "Loss: 0.078252, Train accuracy: 0.996889, val accuracy: 0.776000\n",
      "Loss: 0.056182, Train accuracy: 0.997222, val accuracy: 0.782000\n",
      "Loss: 0.095252, Train accuracy: 0.997444, val accuracy: 0.784000\n",
      "Loss: 0.071091, Train accuracy: 0.997222, val accuracy: 0.780000\n",
      "Loss: 0.074336, Train accuracy: 0.997667, val accuracy: 0.779000\n",
      "Loss: 0.038365, Train accuracy: 0.997444, val accuracy: 0.780000\n",
      "Loss: 0.072346, Train accuracy: 0.997556, val accuracy: 0.782000\n",
      "Loss: 0.057020, Train accuracy: 0.997778, val accuracy: 0.778000\n",
      "Loss: 0.052136, Train accuracy: 0.997778, val accuracy: 0.778000\n",
      "Loss: 0.085907, Train accuracy: 0.997889, val accuracy: 0.780000\n",
      "Loss: 0.083893, Train accuracy: 0.997556, val accuracy: 0.779000\n",
      "Loss: 0.076303, Train accuracy: 0.997444, val accuracy: 0.783000\n",
      "Loss: 0.105318, Train accuracy: 0.997556, val accuracy: 0.778000\n",
      "Loss: 0.137808, Train accuracy: 0.997778, val accuracy: 0.777000\n",
      "Resulting accuracy is 0.777\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 300\n",
      "Loss: 2.222410, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.070816, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.998392, Train accuracy: 0.253556, val accuracy: 0.248000\n",
      "Loss: 1.893611, Train accuracy: 0.291000, val accuracy: 0.296000\n",
      "Loss: 1.925902, Train accuracy: 0.362111, val accuracy: 0.366000\n",
      "Loss: 1.607813, Train accuracy: 0.410000, val accuracy: 0.414000\n",
      "Loss: 1.621255, Train accuracy: 0.441000, val accuracy: 0.445000\n",
      "Loss: 1.497456, Train accuracy: 0.480222, val accuracy: 0.471000\n",
      "Loss: 1.151845, Train accuracy: 0.508000, val accuracy: 0.502000\n",
      "Loss: 1.191277, Train accuracy: 0.540556, val accuracy: 0.536000\n",
      "Loss: 1.442700, Train accuracy: 0.563111, val accuracy: 0.549000\n",
      "Loss: 1.258410, Train accuracy: 0.577111, val accuracy: 0.570000\n",
      "Loss: 1.248842, Train accuracy: 0.596889, val accuracy: 0.578000\n",
      "Loss: 1.350639, Train accuracy: 0.609889, val accuracy: 0.591000\n",
      "Loss: 1.272395, Train accuracy: 0.622889, val accuracy: 0.587000\n",
      "Loss: 1.185601, Train accuracy: 0.627667, val accuracy: 0.601000\n",
      "Loss: 1.497993, Train accuracy: 0.636444, val accuracy: 0.615000\n",
      "Loss: 1.247476, Train accuracy: 0.642333, val accuracy: 0.626000\n",
      "Loss: 1.074190, Train accuracy: 0.646222, val accuracy: 0.625000\n",
      "Loss: 1.327854, Train accuracy: 0.649556, val accuracy: 0.632000\n",
      "Loss: 0.977935, Train accuracy: 0.654111, val accuracy: 0.629000\n",
      "Loss: 1.209374, Train accuracy: 0.658222, val accuracy: 0.629000\n",
      "Loss: 1.284873, Train accuracy: 0.659333, val accuracy: 0.638000\n",
      "Loss: 1.233043, Train accuracy: 0.662111, val accuracy: 0.642000\n",
      "Loss: 1.243555, Train accuracy: 0.665778, val accuracy: 0.642000\n",
      "Loss: 1.015520, Train accuracy: 0.666778, val accuracy: 0.650000\n",
      "Loss: 0.968416, Train accuracy: 0.668889, val accuracy: 0.643000\n",
      "Loss: 1.353569, Train accuracy: 0.670444, val accuracy: 0.651000\n",
      "Loss: 1.315686, Train accuracy: 0.671333, val accuracy: 0.650000\n",
      "Loss: 1.003097, Train accuracy: 0.672889, val accuracy: 0.651000\n",
      "Loss: 1.303919, Train accuracy: 0.673778, val accuracy: 0.654000\n",
      "Loss: 1.030667, Train accuracy: 0.675556, val accuracy: 0.652000\n",
      "Loss: 1.003146, Train accuracy: 0.675889, val accuracy: 0.654000\n",
      "Loss: 1.297115, Train accuracy: 0.677556, val accuracy: 0.653000\n",
      "Loss: 1.162088, Train accuracy: 0.678778, val accuracy: 0.655000\n",
      "Loss: 0.983748, Train accuracy: 0.678444, val accuracy: 0.658000\n",
      "Loss: 1.249652, Train accuracy: 0.680111, val accuracy: 0.658000\n",
      "Loss: 1.098487, Train accuracy: 0.680444, val accuracy: 0.658000\n",
      "Loss: 1.296154, Train accuracy: 0.680556, val accuracy: 0.656000\n",
      "Loss: 1.153726, Train accuracy: 0.680889, val accuracy: 0.659000\n",
      "Loss: 1.169395, Train accuracy: 0.681222, val accuracy: 0.659000\n",
      "Loss: 1.014769, Train accuracy: 0.681667, val accuracy: 0.657000\n",
      "Loss: 1.012462, Train accuracy: 0.681778, val accuracy: 0.659000\n",
      "Loss: 1.130293, Train accuracy: 0.682000, val accuracy: 0.658000\n",
      "Loss: 1.053988, Train accuracy: 0.682778, val accuracy: 0.658000\n",
      "Loss: 1.023580, Train accuracy: 0.683111, val accuracy: 0.658000\n",
      "Loss: 0.868544, Train accuracy: 0.683333, val accuracy: 0.658000\n",
      "Loss: 1.079006, Train accuracy: 0.684111, val accuracy: 0.657000\n",
      "Loss: 1.258664, Train accuracy: 0.684111, val accuracy: 0.657000\n",
      "Loss: 1.519026, Train accuracy: 0.684111, val accuracy: 0.657000\n",
      "Loss: 0.967962, Train accuracy: 0.684667, val accuracy: 0.658000\n",
      "Loss: 0.887749, Train accuracy: 0.685000, val accuracy: 0.658000\n",
      "Loss: 1.351644, Train accuracy: 0.685111, val accuracy: 0.658000\n",
      "Loss: 1.087804, Train accuracy: 0.684778, val accuracy: 0.659000\n",
      "Loss: 1.151803, Train accuracy: 0.685111, val accuracy: 0.658000\n",
      "Loss: 0.864210, Train accuracy: 0.685222, val accuracy: 0.658000\n",
      "Loss: 0.917420, Train accuracy: 0.685111, val accuracy: 0.659000\n",
      "Loss: 0.836566, Train accuracy: 0.685667, val accuracy: 0.658000\n",
      "Loss: 1.168919, Train accuracy: 0.685556, val accuracy: 0.660000\n",
      "Loss: 1.140221, Train accuracy: 0.685667, val accuracy: 0.660000\n",
      "Loss: 1.307329, Train accuracy: 0.685667, val accuracy: 0.660000\n",
      "Loss: 1.197389, Train accuracy: 0.685667, val accuracy: 0.660000\n",
      "Loss: 1.057874, Train accuracy: 0.685778, val accuracy: 0.660000\n",
      "Loss: 1.160192, Train accuracy: 0.685667, val accuracy: 0.660000\n",
      "Loss: 0.885930, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.111266, Train accuracy: 0.685778, val accuracy: 0.660000\n",
      "Loss: 1.008464, Train accuracy: 0.685667, val accuracy: 0.660000\n",
      "Loss: 1.082716, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.226260, Train accuracy: 0.685778, val accuracy: 0.660000\n",
      "Loss: 0.817369, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.061025, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.963464, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.167902, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.063102, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.888605, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.204130, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.241696, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.923099, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.030949, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.103296, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.241164, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.170847, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.138119, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.851662, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.067845, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.822166, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.267751, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.950893, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.203110, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.939098, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.069577, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.985412, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.090332, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.207723, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.954218, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.147577, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.257248, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.882964, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.026521, Train accuracy: 0.686000, val accuracy: 0.660000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.394997, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.237562, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.039319, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.980268, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.146793, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.974715, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.177421, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.244294, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.926464, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.777157, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.887923, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.076559, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.793681, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.249428, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.180838, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.110192, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.937032, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.183970, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.843607, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.940468, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.077549, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.017595, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.159308, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.035341, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.068523, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.189994, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.407301, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.009177, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.020967, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.200524, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.186302, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.227132, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.926172, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.171443, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.186215, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.221542, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.878526, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.241395, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.101949, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.947198, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.164439, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.048839, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.198480, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.065232, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.034277, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.131853, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.063711, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.056142, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.326365, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.210275, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.858425, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.205477, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.003472, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.156800, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.932167, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.030459, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.896596, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.882051, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.121175, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.159744, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.340779, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.149408, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.035112, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.055082, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.214433, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.173655, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.299957, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.284958, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.148072, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.257817, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.902816, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.427539, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.180698, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.978901, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.122576, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.221187, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.976434, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.046434, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.932077, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.308401, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.020197, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.948362, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.138207, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.191573, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.825309, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.893382, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 0.852683, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.006703, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.193282, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.214062, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.241334, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.277848, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.237874, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.059394, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.263451, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.007324, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.274155, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.238168, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.114231, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Loss: 1.206893, Train accuracy: 0.686000, val accuracy: 0.660000\n",
      "Resulting accuracy is 0.66\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 300\n",
      "Loss: 2.150673, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.327860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.132711, Train accuracy: 0.211556, val accuracy: 0.219000\n",
      "Loss: 2.083932, Train accuracy: 0.279556, val accuracy: 0.278000\n",
      "Loss: 2.037449, Train accuracy: 0.349333, val accuracy: 0.354000\n",
      "Loss: 1.567563, Train accuracy: 0.431778, val accuracy: 0.429000\n",
      "Loss: 1.542681, Train accuracy: 0.515667, val accuracy: 0.510000\n",
      "Loss: 1.824474, Train accuracy: 0.562778, val accuracy: 0.553000\n",
      "Loss: 1.348149, Train accuracy: 0.602444, val accuracy: 0.589000\n",
      "Loss: 1.326226, Train accuracy: 0.623000, val accuracy: 0.622000\n",
      "Loss: 1.049621, Train accuracy: 0.661556, val accuracy: 0.642000\n",
      "Loss: 0.969023, Train accuracy: 0.676444, val accuracy: 0.663000\n",
      "Loss: 1.050206, Train accuracy: 0.694889, val accuracy: 0.675000\n",
      "Loss: 1.086099, Train accuracy: 0.711778, val accuracy: 0.698000\n",
      "Loss: 1.011556, Train accuracy: 0.724333, val accuracy: 0.697000\n",
      "Loss: 0.811915, Train accuracy: 0.741222, val accuracy: 0.697000\n",
      "Loss: 0.972110, Train accuracy: 0.749444, val accuracy: 0.706000\n",
      "Loss: 0.600242, Train accuracy: 0.761444, val accuracy: 0.708000\n",
      "Loss: 0.716306, Train accuracy: 0.756333, val accuracy: 0.711000\n",
      "Loss: 0.610828, Train accuracy: 0.770444, val accuracy: 0.716000\n",
      "Loss: 1.002781, Train accuracy: 0.780111, val accuracy: 0.734000\n",
      "Loss: 0.817097, Train accuracy: 0.795889, val accuracy: 0.726000\n",
      "Loss: 0.653914, Train accuracy: 0.797444, val accuracy: 0.728000\n",
      "Loss: 0.413243, Train accuracy: 0.795333, val accuracy: 0.728000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.749836, Train accuracy: 0.816667, val accuracy: 0.738000\n",
      "Loss: 0.488477, Train accuracy: 0.807556, val accuracy: 0.742000\n",
      "Loss: 0.835011, Train accuracy: 0.825556, val accuracy: 0.743000\n",
      "Loss: 0.444186, Train accuracy: 0.834222, val accuracy: 0.745000\n",
      "Loss: 0.547824, Train accuracy: 0.828000, val accuracy: 0.732000\n",
      "Loss: 0.786420, Train accuracy: 0.832778, val accuracy: 0.742000\n",
      "Loss: 0.405384, Train accuracy: 0.839889, val accuracy: 0.748000\n",
      "Loss: 0.831623, Train accuracy: 0.859333, val accuracy: 0.752000\n",
      "Loss: 0.468180, Train accuracy: 0.865556, val accuracy: 0.752000\n",
      "Loss: 0.930553, Train accuracy: 0.857000, val accuracy: 0.747000\n",
      "Loss: 0.555453, Train accuracy: 0.864333, val accuracy: 0.744000\n",
      "Loss: 0.514601, Train accuracy: 0.864778, val accuracy: 0.747000\n",
      "Loss: 0.732195, Train accuracy: 0.868444, val accuracy: 0.743000\n",
      "Loss: 0.530268, Train accuracy: 0.876778, val accuracy: 0.752000\n",
      "Loss: 0.749479, Train accuracy: 0.875556, val accuracy: 0.738000\n",
      "Loss: 0.540171, Train accuracy: 0.884667, val accuracy: 0.745000\n",
      "Loss: 0.433499, Train accuracy: 0.882889, val accuracy: 0.750000\n",
      "Loss: 0.378675, Train accuracy: 0.896889, val accuracy: 0.747000\n",
      "Loss: 0.495609, Train accuracy: 0.895667, val accuracy: 0.759000\n",
      "Loss: 0.574452, Train accuracy: 0.902556, val accuracy: 0.757000\n",
      "Loss: 0.491364, Train accuracy: 0.903333, val accuracy: 0.757000\n",
      "Loss: 0.463321, Train accuracy: 0.913333, val accuracy: 0.756000\n",
      "Loss: 0.317445, Train accuracy: 0.909111, val accuracy: 0.762000\n",
      "Loss: 0.477990, Train accuracy: 0.912889, val accuracy: 0.750000\n",
      "Loss: 0.624178, Train accuracy: 0.914333, val accuracy: 0.756000\n",
      "Loss: 0.437890, Train accuracy: 0.923000, val accuracy: 0.770000\n",
      "Loss: 0.319805, Train accuracy: 0.907556, val accuracy: 0.752000\n",
      "Loss: 0.466936, Train accuracy: 0.925333, val accuracy: 0.764000\n",
      "Loss: 0.243447, Train accuracy: 0.929222, val accuracy: 0.766000\n",
      "Loss: 0.302546, Train accuracy: 0.928222, val accuracy: 0.762000\n",
      "Loss: 0.347952, Train accuracy: 0.932333, val accuracy: 0.773000\n",
      "Loss: 0.473458, Train accuracy: 0.936889, val accuracy: 0.768000\n",
      "Loss: 0.235428, Train accuracy: 0.933222, val accuracy: 0.759000\n",
      "Loss: 0.280098, Train accuracy: 0.938889, val accuracy: 0.758000\n",
      "Loss: 0.606483, Train accuracy: 0.933333, val accuracy: 0.757000\n",
      "Loss: 0.367208, Train accuracy: 0.933444, val accuracy: 0.763000\n",
      "Loss: 0.346055, Train accuracy: 0.930667, val accuracy: 0.755000\n",
      "Loss: 0.232695, Train accuracy: 0.945667, val accuracy: 0.771000\n",
      "Loss: 0.263588, Train accuracy: 0.942222, val accuracy: 0.769000\n",
      "Loss: 0.335651, Train accuracy: 0.948667, val accuracy: 0.774000\n",
      "Loss: 0.322448, Train accuracy: 0.951222, val accuracy: 0.768000\n",
      "Loss: 0.397929, Train accuracy: 0.948778, val accuracy: 0.770000\n",
      "Loss: 0.261367, Train accuracy: 0.953444, val accuracy: 0.766000\n",
      "Loss: 0.219058, Train accuracy: 0.955333, val accuracy: 0.774000\n",
      "Loss: 0.229338, Train accuracy: 0.949778, val accuracy: 0.770000\n",
      "Loss: 0.306086, Train accuracy: 0.954778, val accuracy: 0.782000\n",
      "Loss: 0.258082, Train accuracy: 0.956444, val accuracy: 0.769000\n",
      "Loss: 0.238604, Train accuracy: 0.958333, val accuracy: 0.769000\n",
      "Loss: 0.258714, Train accuracy: 0.952889, val accuracy: 0.775000\n",
      "Loss: 0.274458, Train accuracy: 0.962889, val accuracy: 0.767000\n",
      "Loss: 0.338858, Train accuracy: 0.961111, val accuracy: 0.773000\n",
      "Loss: 0.269265, Train accuracy: 0.957556, val accuracy: 0.781000\n",
      "Loss: 0.230611, Train accuracy: 0.964889, val accuracy: 0.779000\n",
      "Loss: 0.291724, Train accuracy: 0.965556, val accuracy: 0.775000\n",
      "Loss: 0.178469, Train accuracy: 0.964889, val accuracy: 0.771000\n",
      "Loss: 0.494539, Train accuracy: 0.968778, val accuracy: 0.777000\n",
      "Loss: 0.143672, Train accuracy: 0.968000, val accuracy: 0.781000\n",
      "Loss: 0.273286, Train accuracy: 0.966889, val accuracy: 0.770000\n",
      "Loss: 0.185981, Train accuracy: 0.970222, val accuracy: 0.778000\n",
      "Loss: 0.250250, Train accuracy: 0.973222, val accuracy: 0.767000\n",
      "Loss: 0.199596, Train accuracy: 0.971778, val accuracy: 0.775000\n",
      "Loss: 0.217427, Train accuracy: 0.970667, val accuracy: 0.773000\n",
      "Loss: 0.198103, Train accuracy: 0.970111, val accuracy: 0.775000\n",
      "Loss: 0.192571, Train accuracy: 0.974889, val accuracy: 0.778000\n",
      "Loss: 0.374596, Train accuracy: 0.976667, val accuracy: 0.779000\n",
      "Loss: 0.194549, Train accuracy: 0.972889, val accuracy: 0.774000\n",
      "Loss: 0.458776, Train accuracy: 0.974333, val accuracy: 0.776000\n",
      "Loss: 0.195975, Train accuracy: 0.975444, val accuracy: 0.771000\n",
      "Loss: 0.181164, Train accuracy: 0.974556, val accuracy: 0.775000\n",
      "Loss: 0.249598, Train accuracy: 0.977889, val accuracy: 0.780000\n",
      "Loss: 0.176502, Train accuracy: 0.976333, val accuracy: 0.786000\n",
      "Loss: 0.224368, Train accuracy: 0.977778, val accuracy: 0.773000\n",
      "Loss: 0.249309, Train accuracy: 0.976333, val accuracy: 0.780000\n",
      "Loss: 0.256689, Train accuracy: 0.978889, val accuracy: 0.780000\n",
      "Loss: 0.219807, Train accuracy: 0.980222, val accuracy: 0.781000\n",
      "Loss: 0.212433, Train accuracy: 0.981778, val accuracy: 0.780000\n",
      "Loss: 0.208752, Train accuracy: 0.981667, val accuracy: 0.779000\n",
      "Loss: 0.257370, Train accuracy: 0.981889, val accuracy: 0.783000\n",
      "Loss: 0.262498, Train accuracy: 0.980667, val accuracy: 0.781000\n",
      "Loss: 0.212909, Train accuracy: 0.982889, val accuracy: 0.783000\n",
      "Loss: 0.229051, Train accuracy: 0.983222, val accuracy: 0.790000\n",
      "Loss: 0.241408, Train accuracy: 0.984222, val accuracy: 0.778000\n",
      "Loss: 0.187737, Train accuracy: 0.985111, val accuracy: 0.780000\n",
      "Loss: 0.201641, Train accuracy: 0.985111, val accuracy: 0.779000\n",
      "Loss: 0.290447, Train accuracy: 0.984778, val accuracy: 0.778000\n",
      "Loss: 0.276410, Train accuracy: 0.985889, val accuracy: 0.786000\n",
      "Loss: 0.193274, Train accuracy: 0.984778, val accuracy: 0.786000\n",
      "Loss: 0.197249, Train accuracy: 0.985556, val accuracy: 0.780000\n",
      "Loss: 0.160473, Train accuracy: 0.986556, val accuracy: 0.778000\n",
      "Loss: 0.198953, Train accuracy: 0.985778, val accuracy: 0.782000\n",
      "Loss: 0.225970, Train accuracy: 0.987222, val accuracy: 0.781000\n",
      "Loss: 0.176996, Train accuracy: 0.986889, val accuracy: 0.776000\n",
      "Loss: 0.264396, Train accuracy: 0.986556, val accuracy: 0.779000\n",
      "Loss: 0.201036, Train accuracy: 0.987556, val accuracy: 0.781000\n",
      "Loss: 0.208931, Train accuracy: 0.987778, val accuracy: 0.781000\n",
      "Loss: 0.196047, Train accuracy: 0.985556, val accuracy: 0.784000\n",
      "Loss: 0.129058, Train accuracy: 0.988667, val accuracy: 0.780000\n",
      "Loss: 0.196337, Train accuracy: 0.988222, val accuracy: 0.783000\n",
      "Loss: 0.139085, Train accuracy: 0.989778, val accuracy: 0.783000\n",
      "Loss: 0.147445, Train accuracy: 0.989556, val accuracy: 0.781000\n",
      "Loss: 0.170299, Train accuracy: 0.988778, val accuracy: 0.782000\n",
      "Loss: 0.206143, Train accuracy: 0.988222, val accuracy: 0.780000\n",
      "Loss: 0.212483, Train accuracy: 0.987000, val accuracy: 0.777000\n",
      "Loss: 0.319617, Train accuracy: 0.990222, val accuracy: 0.783000\n",
      "Loss: 0.152699, Train accuracy: 0.991444, val accuracy: 0.782000\n",
      "Loss: 0.190808, Train accuracy: 0.990444, val accuracy: 0.781000\n",
      "Loss: 0.166018, Train accuracy: 0.990222, val accuracy: 0.787000\n",
      "Loss: 0.204519, Train accuracy: 0.990667, val accuracy: 0.787000\n",
      "Loss: 0.161691, Train accuracy: 0.991333, val accuracy: 0.783000\n",
      "Loss: 0.156359, Train accuracy: 0.992111, val accuracy: 0.784000\n",
      "Loss: 0.183669, Train accuracy: 0.991444, val accuracy: 0.779000\n",
      "Loss: 0.209891, Train accuracy: 0.990556, val accuracy: 0.781000\n",
      "Loss: 0.175909, Train accuracy: 0.991667, val accuracy: 0.781000\n",
      "Loss: 0.168561, Train accuracy: 0.992222, val accuracy: 0.782000\n",
      "Loss: 0.136334, Train accuracy: 0.992111, val accuracy: 0.788000\n",
      "Loss: 0.148161, Train accuracy: 0.992111, val accuracy: 0.787000\n",
      "Loss: 0.158736, Train accuracy: 0.992667, val accuracy: 0.783000\n",
      "Loss: 0.149762, Train accuracy: 0.991889, val accuracy: 0.786000\n",
      "Loss: 0.158142, Train accuracy: 0.992556, val accuracy: 0.786000\n",
      "Loss: 0.178936, Train accuracy: 0.992000, val accuracy: 0.778000\n",
      "Loss: 0.144376, Train accuracy: 0.993111, val accuracy: 0.784000\n",
      "Loss: 0.173217, Train accuracy: 0.992556, val accuracy: 0.785000\n",
      "Loss: 0.283774, Train accuracy: 0.992111, val accuracy: 0.779000\n",
      "Loss: 0.148364, Train accuracy: 0.992444, val accuracy: 0.786000\n",
      "Loss: 0.183881, Train accuracy: 0.992778, val accuracy: 0.782000\n",
      "Loss: 0.181637, Train accuracy: 0.992889, val accuracy: 0.784000\n",
      "Loss: 0.185009, Train accuracy: 0.993667, val accuracy: 0.784000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.177569, Train accuracy: 0.993889, val accuracy: 0.790000\n",
      "Loss: 0.164513, Train accuracy: 0.993333, val accuracy: 0.783000\n",
      "Loss: 0.159515, Train accuracy: 0.993556, val accuracy: 0.781000\n",
      "Loss: 0.123178, Train accuracy: 0.993556, val accuracy: 0.782000\n",
      "Loss: 0.212560, Train accuracy: 0.994111, val accuracy: 0.785000\n",
      "Loss: 0.210273, Train accuracy: 0.993556, val accuracy: 0.787000\n",
      "Loss: 0.213018, Train accuracy: 0.994111, val accuracy: 0.787000\n",
      "Loss: 0.218715, Train accuracy: 0.994000, val accuracy: 0.784000\n",
      "Loss: 0.195259, Train accuracy: 0.994556, val accuracy: 0.789000\n",
      "Loss: 0.204299, Train accuracy: 0.993889, val accuracy: 0.788000\n",
      "Loss: 0.115430, Train accuracy: 0.994444, val accuracy: 0.784000\n",
      "Loss: 0.256536, Train accuracy: 0.994111, val accuracy: 0.787000\n",
      "Loss: 0.165595, Train accuracy: 0.994111, val accuracy: 0.784000\n",
      "Loss: 0.142740, Train accuracy: 0.994111, val accuracy: 0.785000\n",
      "Loss: 0.147516, Train accuracy: 0.994333, val accuracy: 0.785000\n",
      "Loss: 0.179122, Train accuracy: 0.994778, val accuracy: 0.784000\n",
      "Loss: 0.180528, Train accuracy: 0.994222, val accuracy: 0.787000\n",
      "Loss: 0.142206, Train accuracy: 0.994000, val accuracy: 0.780000\n",
      "Loss: 0.202634, Train accuracy: 0.994889, val accuracy: 0.784000\n",
      "Loss: 0.241284, Train accuracy: 0.994222, val accuracy: 0.790000\n",
      "Loss: 0.204188, Train accuracy: 0.994556, val accuracy: 0.782000\n",
      "Loss: 0.227648, Train accuracy: 0.995000, val accuracy: 0.786000\n",
      "Loss: 0.126255, Train accuracy: 0.994444, val accuracy: 0.785000\n",
      "Loss: 0.198592, Train accuracy: 0.994667, val accuracy: 0.785000\n",
      "Loss: 0.170803, Train accuracy: 0.995333, val accuracy: 0.785000\n",
      "Loss: 0.189807, Train accuracy: 0.994556, val accuracy: 0.784000\n",
      "Loss: 0.143788, Train accuracy: 0.994556, val accuracy: 0.788000\n",
      "Loss: 0.163692, Train accuracy: 0.995000, val accuracy: 0.788000\n",
      "Loss: 0.123337, Train accuracy: 0.995222, val accuracy: 0.784000\n",
      "Loss: 0.197775, Train accuracy: 0.995444, val accuracy: 0.786000\n",
      "Loss: 0.155590, Train accuracy: 0.995222, val accuracy: 0.782000\n",
      "Loss: 0.139866, Train accuracy: 0.995333, val accuracy: 0.788000\n",
      "Loss: 0.195549, Train accuracy: 0.995667, val accuracy: 0.790000\n",
      "Loss: 0.156229, Train accuracy: 0.995222, val accuracy: 0.785000\n",
      "Loss: 0.185809, Train accuracy: 0.996111, val accuracy: 0.787000\n",
      "Loss: 0.130122, Train accuracy: 0.995667, val accuracy: 0.788000\n",
      "Loss: 0.166831, Train accuracy: 0.995222, val accuracy: 0.788000\n",
      "Loss: 0.146639, Train accuracy: 0.995667, val accuracy: 0.793000\n",
      "Loss: 0.125522, Train accuracy: 0.996222, val accuracy: 0.787000\n",
      "Loss: 0.221729, Train accuracy: 0.995778, val accuracy: 0.782000\n",
      "Loss: 0.194393, Train accuracy: 0.996111, val accuracy: 0.783000\n",
      "Loss: 0.142531, Train accuracy: 0.995111, val accuracy: 0.785000\n",
      "Loss: 0.161064, Train accuracy: 0.996000, val accuracy: 0.783000\n",
      "Loss: 0.250571, Train accuracy: 0.995778, val accuracy: 0.784000\n",
      "Loss: 0.175967, Train accuracy: 0.995778, val accuracy: 0.783000\n",
      "Loss: 0.190134, Train accuracy: 0.996000, val accuracy: 0.786000\n",
      "Loss: 0.173250, Train accuracy: 0.996111, val accuracy: 0.788000\n",
      "Loss: 0.218280, Train accuracy: 0.996333, val accuracy: 0.786000\n",
      "Loss: 0.132723, Train accuracy: 0.995333, val accuracy: 0.787000\n",
      "Resulting accuracy is 0.787\n",
      "\n",
      "best validation accuracy achieved: 0.787000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-2]\n",
    "reg_strength = [1e-5, 1e-4]\n",
    "learning_rate_decay = [0.9, 0.99]\n",
    "hidden_layer_size = [300]\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "best_classifier = None\n",
    "best_val_accuracy = -1\n",
    "coef_to_val_accuracy = {}\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "for lr in learning_rates:\n",
    "    for reg in reg_strength:\n",
    "        for lrd in learning_rate_decay:\n",
    "            for hidden_layer_s in hidden_layer_size:\n",
    "                model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_s, reg = reg)\n",
    "                trainer = Trainer(model,\n",
    "                                  dataset,\n",
    "                                  MomentumSGD(),\n",
    "                                  num_epochs = num_epochs,\n",
    "                                  batch_size = batch_size,\n",
    "                                  learning_rate=lr,\n",
    "                                  learning_rate_decay=lrd)\n",
    "                print(f'Fitting: learning rate = {lr}, regularization strength = {reg}, learning rate decay = {lrd}, hidden_layer_size = {hidden_layer_s}' )\n",
    "\n",
    "                loss_history, train_history, val_history = trainer.fit()\n",
    "                coef_to_val_accuracy[(lr, reg, hidden_layer_s)] = val_history[-1]\n",
    "                print(f'Resulting accuracy is {val_history[-1]}\\n')\n",
    "                if val_history[-1] > best_val_accuracy:\n",
    "                    best_classifier = model\n",
    "                    best_val_accuracy = val_history[-1]\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8225ac0690>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.765000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
