{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_0\n",
      "Gradient check passed!\n",
      "Checking gradient for B_0\n",
      "Gradient check passed!\n",
      "Checking gradient for W_2\n",
      "Gradient check passed!\n",
      "Checking gradient for B_2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_0\n",
      "Gradient check passed!\n",
      "Checking gradient for B_0\n",
      "Gradient check passed!\n",
      "Checking gradient for W_2\n",
      "Gradient check passed!\n",
      "Checking gradient for B_2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss_with_reg, loss)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!https://github.com/olegpolivin/dlcourse_ai.git\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.216398, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153856, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.099106, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285874, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.168890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.063678, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.365672, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.103934, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.222549, Train accuracy: 0.210333, val accuracy: 0.218000\n",
      "Loss: 2.059842, Train accuracy: 0.233111, val accuracy: 0.237000\n",
      "Loss: 2.115231, Train accuracy: 0.260667, val accuracy: 0.257000\n",
      "Loss: 2.090787, Train accuracy: 0.272111, val accuracy: 0.275000\n",
      "Loss: 2.098957, Train accuracy: 0.288222, val accuracy: 0.292000\n",
      "Loss: 1.974340, Train accuracy: 0.306889, val accuracy: 0.310000\n",
      "Loss: 2.011588, Train accuracy: 0.333000, val accuracy: 0.336000\n",
      "Loss: 1.819071, Train accuracy: 0.369444, val accuracy: 0.366000\n",
      "Loss: 1.805035, Train accuracy: 0.398222, val accuracy: 0.391000\n",
      "Loss: 2.001364, Train accuracy: 0.415444, val accuracy: 0.405000\n",
      "Loss: 1.930639, Train accuracy: 0.435778, val accuracy: 0.432000\n",
      "Loss: 1.738233, Train accuracy: 0.467111, val accuracy: 0.463000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe2b43961d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe2b42bc610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history, label='Train accuracy')\n",
    "plt.plot(val_history, label='Val accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.245382, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.372504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207905, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259103, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.180887, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191641, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.081185, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.321212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246704, Train accuracy: 0.202778, val accuracy: 0.212000\n",
      "Loss: 2.189141, Train accuracy: 0.231111, val accuracy: 0.238000\n",
      "Loss: 2.074268, Train accuracy: 0.243778, val accuracy: 0.247000\n",
      "Loss: 2.086563, Train accuracy: 0.271111, val accuracy: 0.272000\n",
      "Loss: 2.373452, Train accuracy: 0.278222, val accuracy: 0.275000\n",
      "Loss: 1.735182, Train accuracy: 0.284444, val accuracy: 0.289000\n",
      "Loss: 2.276342, Train accuracy: 0.307667, val accuracy: 0.311000\n",
      "Loss: 1.906094, Train accuracy: 0.339778, val accuracy: 0.338000\n",
      "Loss: 1.673473, Train accuracy: 0.373222, val accuracy: 0.373000\n",
      "Loss: 1.652354, Train accuracy: 0.395778, val accuracy: 0.388000\n",
      "Loss: 1.616790, Train accuracy: 0.415444, val accuracy: 0.411000\n",
      "Loss: 1.999104, Train accuracy: 0.444889, val accuracy: 0.437000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.144626, Train accuracy: 0.197333, val accuracy: 0.206000\n",
      "Loss: 1.622121, Train accuracy: 0.355222, val accuracy: 0.358000\n",
      "Loss: 1.265590, Train accuracy: 0.554000, val accuracy: 0.547000\n",
      "Loss: 1.426333, Train accuracy: 0.609222, val accuracy: 0.590000\n",
      "Loss: 1.316831, Train accuracy: 0.673889, val accuracy: 0.653000\n",
      "Loss: 1.585551, Train accuracy: 0.671222, val accuracy: 0.662000\n",
      "Loss: 0.881241, Train accuracy: 0.727556, val accuracy: 0.678000\n",
      "Loss: 0.963371, Train accuracy: 0.728889, val accuracy: 0.666000\n",
      "Loss: 0.960361, Train accuracy: 0.750222, val accuracy: 0.703000\n",
      "Loss: 1.111276, Train accuracy: 0.773000, val accuracy: 0.697000\n",
      "Loss: 0.505593, Train accuracy: 0.783444, val accuracy: 0.709000\n",
      "Loss: 0.590929, Train accuracy: 0.811667, val accuracy: 0.725000\n",
      "Loss: 0.583194, Train accuracy: 0.829333, val accuracy: 0.728000\n",
      "Loss: 0.286914, Train accuracy: 0.804000, val accuracy: 0.719000\n",
      "Loss: 1.040563, Train accuracy: 0.835000, val accuracy: 0.731000\n",
      "Loss: 0.458959, Train accuracy: 0.829111, val accuracy: 0.744000\n",
      "Loss: 0.643442, Train accuracy: 0.835778, val accuracy: 0.732000\n",
      "Loss: 0.731865, Train accuracy: 0.836111, val accuracy: 0.727000\n",
      "Loss: 0.157285, Train accuracy: 0.869444, val accuracy: 0.763000\n",
      "Loss: 0.417178, Train accuracy: 0.863222, val accuracy: 0.741000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351801, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319693, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.295926, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.345443, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310013, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.326544, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.255641, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199259, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.164561, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.025661, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883798, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.263931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.662918, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.245522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943906, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.663953, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.042200, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.418303, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.519709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.823944, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.585656, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937038, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908215, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.233499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.095108, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.718242, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.162756, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.015933, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.363952, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.842670, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.657567, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.388463, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.911120, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.693765, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.010436, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.115900, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613706, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.738574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.885192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.474042, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.119274, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.672047, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.767860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.478802, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.926619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.337383, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.683186, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.660081, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.401881, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.635264, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.635617, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.622938, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.854111, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.556636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634732, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.076198, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.007559, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.531114, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.041336, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.022564, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369538, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.379903, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.986917, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318972, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.283966, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936269, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.196061, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.739352, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.201189, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.582981, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.742143, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.293135, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.748190, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.976545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.357876, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.992895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602046, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602167, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.173057, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.312798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.564551, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.961713, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.274091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.304703, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.958926, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.377168, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.657193, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.389767, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.576803, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.556738, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.175409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322616, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.251510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.060407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.661861, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227308, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.597969, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.887250, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.338688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.842966, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.160604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.347215, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223119, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.436648, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.535320, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249121, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.248964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.549803, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.259687, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097239, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.324286, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.315431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.420746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443017, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.301618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.533658, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.607993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.239065, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.649177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.602848, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.363682, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.197888, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.126413, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.008120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.643235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.592807, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412599, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.212850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196541, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.280346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.403204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229377, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.102808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.445285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219193, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449330, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.304464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.494726, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.361608, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.424061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.303493, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.272501, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.112325, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.223673, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.279593, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.022219, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.724254, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.406655, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.777473, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.856513, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.829882, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 0.995744, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 0.922113, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.554490, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.440609, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.336933, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.380880, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.278951, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.291828, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.060600, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=0.33, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea will be the following: first, we choose among large range of parameters, and then I will adjust further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.648\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.658\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.664\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.776\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.768\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.785\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.778\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.764\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.778\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.639\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.651\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.669\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.77\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.773\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.782\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.765\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.77\n",
      "\n",
      "Fitting: learning rate = 0.01, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.772\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.773\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.779\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.789\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.739\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.761\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.771\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.749\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.749\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.741\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.78\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.762\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.781\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.771\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.774\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.786\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.722\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.706\n",
      "\n",
      "Fitting: learning rate = 0.1, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.71\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iorana/Desktop/storytelling/ML/education/dlcourse_ai/assignments/assignment2/layers.py:64: RuntimeWarning: divide by zero encountered in log\n",
      "  H = -np.mean(np.log(probs[row_index, target_index]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting accuracy is 0.242\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.315\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.9, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.406\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iorana/Desktop/storytelling/ML/education/dlcourse_ai/assignments/assignment2/layers.py:39: RuntimeWarning: overflow encountered in subtract\n",
      "  probs = predictions - np.max(predictions, axis=1)[:, np.newaxis]\n",
      "/home/iorana/Desktop/storytelling/ML/education/dlcourse_ai/assignments/assignment2/layers.py:39: RuntimeWarning: invalid value encountered in subtract\n",
      "  probs = predictions - np.max(predictions, axis=1)[:, np.newaxis]\n",
      "/home/iorana/Desktop/storytelling/ML/education/dlcourse_ai/assignments/assignment2/model.py:60: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss_reg += np.sum(param.value**2)\n",
      "/home/iorana/Desktop/storytelling/ML/education/dlcourse_ai/assignments/assignment2/layers.py:135: RuntimeWarning: invalid value encountered in greater\n",
      "  d_result = np.multiply(d_out, X > 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iorana/anaconda3/envs/torch/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.99, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 1e-05, learning rate decay = 0.999, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.219\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.309\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.9, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.425\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.99, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 100\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 200\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "Fitting: learning rate = 0.35, regularization strength = 0.0001, learning rate decay = 0.999, hidden_layer_size = 300\n",
      "Resulting accuracy is 0.049\n",
      "\n",
      "best validation accuracy achieved: 0.789000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-2, 1e-1, 0.35]\n",
    "reg_strength = [1e-5, 1e-4]\n",
    "learning_rate_decay = [0.9, 0.99, 0.999]\n",
    "hidden_layer_size = [100, 200, 300]\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "best_classifier = None\n",
    "best_val_accuracy = -1\n",
    "coef_to_val_accuracy = {}\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "for lr in learning_rates:\n",
    "    for reg in reg_strength:\n",
    "        for lrd in learning_rate_decay:\n",
    "            for hidden_layer_s in hidden_layer_size:\n",
    "                model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_s, reg = reg)\n",
    "                trainer = Trainer(model,\n",
    "                                  dataset,\n",
    "                                  MomentumSGD(),\n",
    "                                  num_epochs = num_epochs,\n",
    "                                  batch_size = batch_size,\n",
    "                                  learning_rate=lr,\n",
    "                                  learning_rate_decay=lrd)\n",
    "                print(f'Fitting: learning rate = {lr}, regularization strength = {reg}, learning rate decay = {lrd}, hidden_layer_size = {hidden_layer_s}' )\n",
    "\n",
    "                loss_history, train_history, val_history = trainer.fit()\n",
    "                coef_to_val_accuracy[(lr, reg, hidden_layer_s)] = val_history[-1]\n",
    "                print(f'Resulting accuracy is {val_history[-1]}\\n')\n",
    "                if val_history[-1] > best_val_accuracy:\n",
    "                    best_classifier = model\n",
    "                    best_val_accuracy = val_history[-1]\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe2b41ea810>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.750000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
